{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c05c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 15 17:21:32 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              70W / 400W |  17245MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  | 00000002:00:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              70W / 400W |  17055MiB / 81920MiB |     26%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          On  | 00000003:00:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              81W / 400W |  17055MiB / 81920MiB |     38%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          On  | 00000004:00:00.0 Off |                    0 |\n",
      "| N/A   33C    P0              67W / 400W |  17389MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM4-80GB          On  | 0000000B:00:00.0 Off |                    0 |\n",
      "| N/A   34C    P0              70W / 400W |  17055MiB / 81920MiB |     10%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM4-80GB          On  | 0000000C:00:00.0 Off |                    0 |\n",
      "| N/A   34C    P0              68W / 400W |  33212MiB / 81920MiB |     16%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM4-80GB          On  | 0000000D:00:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              69W / 400W |  17389MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM4-80GB          On  | 0000000E:00:00.0 Off |                    0 |\n",
      "| N/A   35C    P0              66W / 400W |  16911MiB / 81920MiB |     19%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6b002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b894f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_combine import MM_LLMs, MM_LLMs_Config\n",
    "from transformers import AutoModelForCausalLM, CLIPProcessor, CLIPModel,AutoModel, AutoTokenizer, AutoProcessor,AutoConfig,CLIPConfig, LlamaConfig, WhisperConfig, WhisperModel, LlamaModel, LlamaTokenizer\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from streaming import LocalDataset\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0161a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "MM_LLMs.register_for_auto_class()\n",
    "MM_LLMs_Config.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9b740b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multimodal-tinyllama/checkpoint-6700'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "latest = get_last_checkpoint('multimodal-tinyllama')\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b6dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    }
   ],
   "source": [
    "model = MM_LLMs.from_pretrained(\n",
    "    latest,flash_attention = True, dtype = torch.bfloat16, torch_dtype = torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d90435",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08fdb43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "image_processor = AutoProcessor.from_pretrained('google/siglip-base-patch16-384')\n",
    "audio_processor = AutoProcessor.from_pretrained('mesolitica/malaysian-whisper-small')\n",
    "tokenizer = AutoTokenizer.from_pretrained(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0aa42347",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_height = image_processor.image_processor.size['height']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "164c0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e2279b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(messages, images: List[str] = None, audio: List[str] = None, sr = 16000):\n",
    "    \n",
    "    if images is not None:\n",
    "        images = [Image.open(f).convert('RGB') for f in images]\n",
    "        image_output = image_processor(images=images, return_tensors='pt')['pixel_values']\n",
    "    else:\n",
    "        image_output = None\n",
    "        \n",
    "    if audio is not None:\n",
    "        audio = [librosa.load(f, sr=sr)[0] for f in audio]\n",
    "        audio_features = audio_processor(audio, sampling_rate=sr, return_tensors='pt',)['input_features']\n",
    "    else:\n",
    "        audio_features = None\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize = False)\n",
    "    outputs = tokenizer(\n",
    "                    prompt,\n",
    "                    return_tensors='pt',\n",
    "                    return_overflowing_tokens=False,\n",
    "                    return_length=False\n",
    "    )\n",
    "\n",
    "    outputs['images'] = image_output\n",
    "    outputs['audios'] = audio_features\n",
    "    \n",
    "    image_token = tokenizer.convert_tokens_to_ids('<image>')\n",
    "    audio_token = tokenizer.convert_tokens_to_ids('<audio>')\n",
    "    \n",
    "    if image_output is not None:\n",
    "        outputs['image_index'] = torch.tensor([0] * len(outputs['images']))\n",
    "        outputs['image_starts'] = torch.tensor([image_token] * len(outputs['images']))\n",
    "    else:\n",
    "        outputs['image_index'] = torch.tensor([])\n",
    "        outputs['image_starts'] = torch.tensor([image_token])\n",
    "        \n",
    "    if audio_features is not None:\n",
    "        outputs['audio_index'] = torch.tensor([0] * len(outputs['audios']))\n",
    "        outputs['audio_starts'] = torch.tensor([audio_token] * len(outputs['audios']))\n",
    "    else:\n",
    "        outputs['audio_index'] = torch.tensor([])\n",
    "        outputs['audio_starts'] = torch.tensor([audio_token])\n",
    "        \n",
    "    where_is = torch.where((outputs['input_ids'] == image_token) | (outputs['input_ids'] == audio_token))\n",
    "    ls = []\n",
    "    for i in range(len(where_is[0])):\n",
    "        b, k = where_is[0][i], where_is[1][i]\n",
    "        l = int(outputs['input_ids'][b, k])\n",
    "        ls.append(l)\n",
    "\n",
    "    ls = torch.tensor(ls)\n",
    "    outputs['where_is_b'] = where_is[0]\n",
    "    outputs['where_is_k'] = where_is[1]\n",
    "    outputs['ls'] = ls\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb3e6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://cdn.beautifulnara.net/wp-content/uploads/2017/12/10201620/Persian-cat-breed.jpg\n",
    "# !wget https://www.jocooks.com/wp-content/uploads/2023/09/nasi-goreng-1-23.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f479cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = 'translated-LLaVA-Instruct-150K/filtered-llava-images/000000033471.jpg'\n",
    "test_image2 = 'Persian-cat-breed.jpg'\n",
    "test_image3 = 'abang-gay.png'\n",
    "test_image4 = 'nasi-goreng-1-23.jpg'\n",
    "images = [\n",
    "    test_image,\n",
    "    test_image2,\n",
    "    test_image3,\n",
    "    test_image4\n",
    "]\n",
    "audio = 'test.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dff856ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated-LLaVA-Instruct-150K/filtered-llava-images/000000033471.jpg <s>Imej ini adalah pandangan gambar hidupan liar yang berkemungkinan menghalakan matamanya di jalan bandar. Terdapat juga gambar bas jalanan yang lalu.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persian-cat-breed.jpg <s>Ini adalah imej seekor kucing putih berkaki panjang dan gebu dengan mata yang berkibir dan ekspresi yang mesra dan tenang.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abang-gay.png <s>Imej itu menunjukkan seorang lelaki yang memakai baju merah dan hitam. Dia berdiri teguh di kawasan yang dipenuhi dengan batu.</s>\n",
      "nasi-goreng-1-23.jpg <s>Imej ini adalah gambar makan malam. Ia menangkap mangkuk nasi, sayur-sayuran, dan roti yang dihidangkan bersama hidangan. Hidangan nasi dan sayur-sayuran menjadi persembahan yang menarik dan berwarna-warp.\n",
      "\n",
      "Secara keseluruhan, terdapat sekurang-kurangnya lapan keping sayur-sayuran dan tujuh keping roti dalam gambar ini. Sama ada di atas atau di bawah mangkuk, ia semuanya sama dan menyediakan pilihan persembahan yang hampir sama.</s>\n"
     ]
    }
   ],
   "source": [
    "for img in images:\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': '<image> </image> ini gambar apa'},\n",
    "    ]\n",
    "    outputs = prepare_dataset(messages, images = [img])\n",
    "    if outputs['images'] is not None:\n",
    "        outputs['images'] = outputs['images'].type(model.dtype)\n",
    "    if outputs['audios'] is not None:\n",
    "        outputs['audios'] = outputs['audios'].type(model.dtype)\n",
    "    for k in outputs.keys():\n",
    "        if outputs[k] is not None:\n",
    "            outputs[k] = outputs[k].cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_inputs = model.prepare_inputs_for_generation(**outputs, inference = True)\n",
    "\n",
    "    r = model_inputs.pop('input_ids', None)\n",
    "    generate_kwargs = dict(\n",
    "        model_inputs,\n",
    "        max_new_tokens=300,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        temperature=0.9,\n",
    "        do_sample=True,\n",
    "        num_beams=1,\n",
    "    )\n",
    "\n",
    "    r = model.llm.generate(**generate_kwargs)\n",
    "    print(img, tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fa97fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Gambar-gambar ini tidak berkaitan, kerana mereka merupakan penerangan tentang tiga haiwan yang berbeza.</s>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'user', 'content': '<image> </image> <image> </image> apa kaitan 2 gambar ni'},\n",
    "]\n",
    "outputs = prepare_dataset(messages, images = [test_image, test_image2])\n",
    "if outputs['images'] is not None:\n",
    "    outputs['images'] = outputs['images'].type(model.dtype)\n",
    "if outputs['audios'] is not None:\n",
    "    outputs['audios'] = outputs['audios'].type(model.dtype)\n",
    "for k in outputs.keys():\n",
    "    if outputs[k] is not None:\n",
    "        outputs[k] = outputs[k].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_inputs = model.prepare_inputs_for_generation(**outputs, inference = True)\n",
    "    \n",
    "r = model_inputs.pop('input_ids', None)\n",
    "generate_kwargs = dict(\n",
    "    model_inputs,\n",
    "    max_new_tokens=300,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    temperature=0.9,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    ")\n",
    "\n",
    "r = model.llm.generate(**generate_kwargs)\n",
    "print(tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f3f3e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>powerlift lagi boleh bagi RM300.</s>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'user', 'content': '<audio> </audio> apa isu audio ni'},\n",
    "]\n",
    "outputs = prepare_dataset(messages, images = [test_image], audio = [audio])\n",
    "if outputs['images'] is not None:\n",
    "    outputs['images'] = outputs['images'].type(model.dtype)\n",
    "if outputs['audios'] is not None:\n",
    "    outputs['audios'] = outputs['audios'].type(model.dtype)\n",
    "for k in outputs.keys():\n",
    "    if outputs[k] is not None:\n",
    "        outputs[k] = outputs[k].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_inputs = model.prepare_inputs_for_generation(**outputs, inference = True)\n",
    "    \n",
    "r = model_inputs.pop('input_ids', None)\n",
    "generate_kwargs = dict(\n",
    "    model_inputs,\n",
    "    max_new_tokens=300,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    temperature=0.9,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    ")\n",
    "\n",
    "r = model.llm.generate(**generate_kwargs)\n",
    "print(tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d895137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Gambar dan audio ini nampaknya berkaitan antara satu sama lain. Gambar menunjukkan sebuah bas dua tingkat dalam perjalanan menuruni jalan yang sibuk. Adegan ini mewujudkan rasa mendesak, kerana penumpang mencari pilihan pembayaran yang lebih berkesan untuk mendapatkan bantuan kewangan.\n",
      "\n",
      "Sementara itu, audio ini memaparkan perbincangan tentang membuat pembayaran besar seperti 500 ringgit kepada perkhidmatan kewangan, dengan menyatakan bahawa tidak ada sistem e-watak yang tersedia di Malaysia. Penceramah juga membincangkan kelemahan sistem sedemikian, kerana mereka tidak menyediakan bantuan yang diperlukan untuk isu kewangan.</s>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'user', 'content': '<image> </image> <audio> </audio> apa kaitan gambar dan audio ni'},\n",
    "]\n",
    "outputs = prepare_dataset(messages, images = [test_image], audio = [audio])\n",
    "if outputs['images'] is not None:\n",
    "    outputs['images'] = outputs['images'].type(model.dtype)\n",
    "if outputs['audios'] is not None:\n",
    "    outputs['audios'] = outputs['audios'].type(model.dtype)\n",
    "for k in outputs.keys():\n",
    "    if outputs[k] is not None:\n",
    "        outputs[k] = outputs[k].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_inputs = model.prepare_inputs_for_generation(**outputs, inference = True)\n",
    "    \n",
    "r = model_inputs.pop('input_ids', None)\n",
    "generate_kwargs = dict(\n",
    "    model_inputs,\n",
    "    max_new_tokens=300,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    temperature=0.9,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    ")\n",
    "\n",
    "r = model.llm.generate(**generate_kwargs)\n",
    "print(tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ac3fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image.open('abang-gay.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "718c0b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/utils/hub.py:667: UserWarning: The `organization` argument is deprecated and will be removed in v5 of Transformers. Set your organization directly in the `repo_id` passed instead (`repo_id={organization}/{model_id}`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb11a14ad7d4bc59993d8b1100efb2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-tinyllama-1.1b-mmmmodal/commit/494b2c7c7b9e80da0fefdca1e5dd53688ce38457', commit_message='Upload MM_LLMs', commit_description='', oid='494b2c7c7b9e80da0fefdca1e5dd53688ce38457', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('malaysian-tinyllama-1.1b-mmmmodal', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98862dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/utils/hub.py:667: UserWarning: The `organization` argument is deprecated and will be removed in v5 of Transformers. Set your organization directly in the `repo_id` passed instead (`repo_id={organization}/{model_id}`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-tinyllama-1.1b-mmmmodal/commit/49977969dc09c58de42c0cc32727c67f72f87c6e', commit_message='Upload processor', commit_description='', oid='49977969dc09c58de42c0cc32727c67f72f87c6e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_processor.push_to_hub('malaysian-tinyllama-1.1b-mmmmodal', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "239c72d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-tinyllama-1.1b-mmmmodal/commit/81bca0f61f1ac646a10829344ad4d3c87172a22a', commit_message='Upload processor', commit_description='', oid='81bca0f61f1ac646a10829344ad4d3c87172a22a', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_processor.push_to_hub('malaysian-tinyllama-1.1b-mmmmodal', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfa9233d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-tinyllama-1.1b-mmmmodal/commit/b1f6d37be94bdc29fe4df78813b8af9f6e86412c', commit_message='Upload tokenizer', commit_description='', oid='b1f6d37be94bdc29fe4df78813b8af9f6e86412c', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub('malaysian-tinyllama-1.1b-mmmmodal', organization='mesolitica', safe_serialization=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
