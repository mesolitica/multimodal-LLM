{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c05c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 17 00:03:18 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   59C    P0             371W / 400W |  69997MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  | 00000002:00:00.0 Off |                    0 |\n",
      "| N/A   54C    P0             377W / 400W |  47435MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          On  | 00000003:00:00.0 Off |                    0 |\n",
      "| N/A   55C    P0             338W / 400W |  48139MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          On  | 00000004:00:00.0 Off |                    0 |\n",
      "| N/A   55C    P0             407W / 400W |  63639MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM4-80GB          On  | 0000000B:00:00.0 Off |                    0 |\n",
      "| N/A   57C    P0             353W / 400W |  43867MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM4-80GB          On  | 0000000C:00:00.0 Off |                    0 |\n",
      "| N/A   54C    P0             376W / 400W |  65865MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM4-80GB          On  | 0000000D:00:00.0 Off |                    0 |\n",
      "| N/A   57C    P0             419W / 400W |  66395MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM4-80GB          On  | 0000000E:00:00.0 Off |                    0 |\n",
      "| N/A   55C    P0             402W / 400W |  72941MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6b002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b894f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_combine import MM_LLMs, MM_LLMs_Config\n",
    "from transformers import AutoModelForCausalLM, CLIPProcessor, CLIPModel,AutoModel, AutoTokenizer, AutoProcessor,AutoConfig,CLIPConfig, LlamaConfig, WhisperConfig, WhisperModel, LlamaModel, LlamaTokenizer\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from streaming import LocalDataset\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0161a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "MM_LLMs.register_for_auto_class()\n",
    "MM_LLMs_Config.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9b740b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'multimodal-tinyllama/checkpoint-6700'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "latest = get_last_checkpoint('multimodal-tinyllama')\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b6dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    }
   ],
   "source": [
    "model = MM_LLMs.from_pretrained(\n",
    "    latest,flash_attention = True, dtype = torch.bfloat16, torch_dtype = torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d90435",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08fdb43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "image_processor = AutoProcessor.from_pretrained('google/siglip-base-patch16-384')\n",
    "audio_processor = AutoProcessor.from_pretrained('mesolitica/malaysian-whisper-small')\n",
    "tokenizer = AutoTokenizer.from_pretrained(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "164c0bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e2279b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(messages, images: List[str] = None, audio: List[str] = None, sr = 16000):\n",
    "    \n",
    "    if images is not None:\n",
    "        images = [Image.open(f).convert('RGB') for f in images]\n",
    "        image_output = image_processor(images=images, return_tensors='pt')['pixel_values']\n",
    "    else:\n",
    "        image_output = None\n",
    "        \n",
    "    if audio is not None:\n",
    "        audio = [librosa.load(f, sr=sr)[0] for f in audio]\n",
    "        audio_features = audio_processor(audio, sampling_rate=sr, return_tensors='pt',)['input_features']\n",
    "    else:\n",
    "        audio_features = None\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize = False)\n",
    "    outputs = tokenizer(\n",
    "                    prompt,\n",
    "                    return_tensors='pt',\n",
    "                    return_overflowing_tokens=False,\n",
    "                    return_length=False\n",
    "    )\n",
    "\n",
    "    outputs['images'] = image_output\n",
    "    outputs['audios'] = audio_features\n",
    "    \n",
    "    image_token = tokenizer.convert_tokens_to_ids('<image>')\n",
    "    audio_token = tokenizer.convert_tokens_to_ids('<audio>')\n",
    "    \n",
    "    if image_output is not None:\n",
    "        len_image = len(image_output)\n",
    "    else:\n",
    "        len_image = 0\n",
    "        \n",
    "    if audio_features is not None:\n",
    "        len_audio = len(audio_features)\n",
    "    else:\n",
    "        len_audio = 0\n",
    "        \n",
    "    outputs['image_index'] = torch.tensor([0] * len_image)\n",
    "    outputs['image_starts'] = torch.tensor([image_token] * (len_image + 1))\n",
    "    outputs['audio_index'] = torch.tensor([0] * len_audio)\n",
    "    outputs['audio_starts'] = torch.tensor([audio_token] * (len_audio + 1))\n",
    "        \n",
    "    where_is = torch.where((outputs['input_ids'] == image_token) | (outputs['input_ids'] == audio_token))\n",
    "    ls = []\n",
    "    for i in range(len(where_is[0])):\n",
    "        b, k = where_is[0][i], where_is[1][i]\n",
    "        l = int(outputs['input_ids'][b, k])\n",
    "        ls.append(l)\n",
    "\n",
    "    ls = torch.tensor(ls)\n",
    "    outputs['where_is_b'] = where_is[0]\n",
    "    outputs['where_is_k'] = where_is[1]\n",
    "    outputs['ls'] = ls\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb3e6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://cdn.beautifulnara.net/wp-content/uploads/2017/12/10201620/Persian-cat-breed.jpg\n",
    "# !wget https://www.jocooks.com/wp-content/uploads/2023/09/nasi-goreng-1-23.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f479cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = 'translated-LLaVA-Instruct-150K/filtered-llava-images/000000033471.jpg'\n",
    "test_image2 = 'Persian-cat-breed.jpg'\n",
    "test_image3 = 'abang-gay.png'\n",
    "test_image4 = 'nasi-goreng-1-23.jpg'\n",
    "images = [\n",
    "    test_image,\n",
    "    test_image2,\n",
    "    test_image3,\n",
    "    test_image4\n",
    "]\n",
    "audio = 'test.mp3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dff856ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "translated-LLaVA-Instruct-150K/filtered-llava-images/000000033471.jpg <s>Dalam imej, terdapat bas bandar pada waktu siang. Ia mempunyai grafiti di atasnya, mungkin untuk meningkatkan penampilannya atau mengubahnya menjadi promosi. Bas itu juga mempunyai iklan yang ditayangkan pada sisi untuk promosi.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persian-cat-breed.jpg <s>Imej ini mempamerkan kucing putih yang terletak dalam kedudukan yang selesa, dengan kepalanya menghadap ke luar di atas sofa hitam. Kucing sedang berehat di atas sofa, sama seperti semasa ia berehat.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abang-gay.png <s>Dalam imej ini, terdapat seorang lelaki muda yang bergambar di sebelah beg pakaian yang dipakai di atas leher.</s>\n",
      "nasi-goreng-1-23.jpg <s>Imej ini adalah imej makan malam dengan kuali nasi di atas meja. Nasi dihidangkan pada pinggan putih dan telah dipotong menjadi kepingan yang lebih kecil. Terdapat beberapa lobak merah, kedua-duanya dihidangkan pada pinggan dan di atas meja. Makan malam termasuk berapa jenis sayur-sayuran dan hidangan utama?</s>\n"
     ]
    }
   ],
   "source": [
    "for img in images:\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': '<image> </image> ini gambar apa'},\n",
    "    ]\n",
    "    outputs = prepare_dataset(messages, images = [img])\n",
    "    if outputs['images'] is not None:\n",
    "        outputs['images'] = outputs['images'].type(model.dtype)\n",
    "    if outputs['audios'] is not None:\n",
    "        outputs['audios'] = outputs['audios'].type(model.dtype)\n",
    "    for k in outputs.keys():\n",
    "        if outputs[k] is not None:\n",
    "            outputs[k] = outputs[k].cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_inputs = model.prepare_inputs_for_generation(**outputs, inference = True)\n",
    "\n",
    "    r = model_inputs.pop('input_ids', None)\n",
    "    generate_kwargs = dict(\n",
    "        model_inputs,\n",
    "        max_new_tokens=300,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        temperature=0.9,\n",
    "        do_sample=True,\n",
    "        num_beams=1,\n",
    "    )\n",
    "\n",
    "    r = model.llm.generate(**generate_kwargs)\n",
    "    print(img, tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6fa97fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Imej pertama adalah tentang bas pelancongan tertentu yang dibawa di jalan. Imej kedua, pula, merakamkan kucing putih yang terletak di atas permaidani, mungkin memerhatikan persekitarannya atau cuba melindunginya daripada pemergiannya yang akan datang.</s>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'user', 'content': '<image> </image> <image> </image> apa kaitan 2 gambar ni'},\n",
    "]\n",
    "outputs = prepare_dataset(messages, images = [test_image, test_image2])\n",
    "if outputs['images'] is not None:\n",
    "    outputs['images'] = outputs['images'].type(model.dtype)\n",
    "if outputs['audios'] is not None:\n",
    "    outputs['audios'] = outputs['audios'].type(model.dtype)\n",
    "for k in outputs.keys():\n",
    "    if outputs[k] is not None:\n",
    "        outputs[k] = outputs[k].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_inputs = model.prepare_inputs_for_generation(**outputs, inference = True)\n",
    "    \n",
    "r = model_inputs.pop('input_ids', None)\n",
    "generate_kwargs = dict(\n",
    "    model_inputs,\n",
    "    max_new_tokens=300,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    temperature=0.9,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    ")\n",
    "\n",
    "r = model.llm.generate(**generate_kwargs)\n",
    "print(tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f3f3e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> mondiat lagi boleh bagi RM300-RM500 kepada 500 orang. Dan sekarang, mereka tidak faham tujuan objektifnya. Ini untuk menggalakkan orang menggunakan e-wallet. Tetapi, di Malaysia, jika seseorang menghadapi masalah, mereka tidak dapat mengeluarkan wang e-wallet mereka. Sebab itu, tiada sistem yang betul dalam sistem e-wallet di Malaysia.</s>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'user', 'content': '<audio> </audio> apa isu audio ni'},\n",
    "]\n",
    "outputs = prepare_dataset(messages, images = [test_image], audio = [audio])\n",
    "if outputs['images'] is not None:\n",
    "    outputs['images'] = outputs['images'].type(model.dtype)\n",
    "if outputs['audios'] is not None:\n",
    "    outputs['audios'] = outputs['audios'].type(model.dtype)\n",
    "for k in outputs.keys():\n",
    "    if outputs[k] is not None:\n",
    "        outputs[k] = outputs[k].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_inputs = model.prepare_inputs_for_generation(**outputs, inference = True)\n",
    "    \n",
    "r = model_inputs.pop('input_ids', None)\n",
    "generate_kwargs = dict(\n",
    "    model_inputs,\n",
    "    max_new_tokens=300,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    temperature=0.9,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    ")\n",
    "\n",
    "r = model.llm.generate(**generate_kwargs)\n",
    "print(tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d895137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Potongan gambar dan audio yang anda berikan berkata \"Anda boleh memberi 300 ringgit ke dalam sistem pemikiran anda, 500 ringgit ke arah penciptaan e-wallet, mengapa orang tidak memahami objektifnya? Mengapa orang tidak mengikut nasihat? Berapa banyak masalahnya di Malaysia? Anda pergi tempat yang tidak selamat. Anda pergi tempat yang tidak selamat, anda pergi tempat yang tidak selamat, anda pergi tempat yang tidak selamat. Anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran, anda pergi ke pasaran,\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'user', 'content': '<image> </image> <audio> </audio> apa kaitan gambar dan audio ni'},\n",
    "]\n",
    "outputs = prepare_dataset(messages, images = [test_image], audio = [audio])\n",
    "if outputs['images'] is not None:\n",
    "    outputs['images'] = outputs['images'].type(model.dtype)\n",
    "if outputs['audios'] is not None:\n",
    "    outputs['audios'] = outputs['audios'].type(model.dtype)\n",
    "for k in outputs.keys():\n",
    "    if outputs[k] is not None:\n",
    "        outputs[k] = outputs[k].cuda()\n",
    "\n",
    "with torch.no_grad():\n",
    "    model_inputs = model.prepare_inputs_for_generation(**outputs, inference = True)\n",
    "    \n",
    "r = model_inputs.pop('input_ids', None)\n",
    "generate_kwargs = dict(\n",
    "    model_inputs,\n",
    "    max_new_tokens=300,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    temperature=0.9,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    ")\n",
    "\n",
    "r = model.llm.generate(**generate_kwargs)\n",
    "print(tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ac3fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image.open('abang-gay.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub('malaysian-tinyllama-1.1b-mmmmodal', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98862dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor.push_to_hub('malaysian-tinyllama-1.1b-mmmmodal', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239c72d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_processor.push_to_hub('malaysian-tinyllama-1.1b-mmmmodal', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub('malaysian-tinyllama-1.1b-mmmmodal', organization='mesolitica', safe_serialization=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
