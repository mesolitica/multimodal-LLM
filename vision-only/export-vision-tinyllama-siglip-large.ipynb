{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c05c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 12 01:59:09 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   54C    P0             257W / 400W |  63225MiB / 81920MiB |     29%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  | 00000002:00:00.0 Off |                    0 |\n",
      "| N/A   47C    P0             230W / 400W |  63211MiB / 81920MiB |     30%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          On  | 00000003:00:00.0 Off |                    0 |\n",
      "| N/A   51C    P0             258W / 400W |  63341MiB / 81920MiB |     34%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          On  | 00000004:00:00.0 Off |                    0 |\n",
      "| N/A   50C    P0             398W / 400W |  70383MiB / 81920MiB |     61%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM4-80GB          On  | 0000000B:00:00.0 Off |                    0 |\n",
      "| N/A   52C    P0             350W / 400W |  61285MiB / 81920MiB |     33%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM4-80GB          On  | 0000000C:00:00.0 Off |                    0 |\n",
      "| N/A   48C    P0             353W / 400W |  61253MiB / 81920MiB |     65%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM4-80GB          On  | 0000000D:00:00.0 Off |                    0 |\n",
      "| N/A   51C    P0             319W / 400W |  63315MiB / 81920MiB |     71%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM4-80GB          On  | 0000000E:00:00.0 Off |                    0 |\n",
      "| N/A   50C    P0             238W / 400W |  63657MiB / 81920MiB |     35%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6b002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b894f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_vision import MM_LLMs, MM_LLMs_Config\n",
    "from transformers import AutoModelForCausalLM, CLIPProcessor, CLIPModel,AutoModel, AutoTokenizer, AutoProcessor,AutoConfig,CLIPConfig, LlamaConfig, WhisperConfig, WhisperModel, LlamaModel, LlamaTokenizer\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from streaming import LocalDataset\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0161a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "MM_LLMs.register_for_auto_class()\n",
    "MM_LLMs_Config.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9b740b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vision-tinyllama-siglip-large/checkpoint-5900'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "latest = get_last_checkpoint('vision-tinyllama-siglip-large')\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b6dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    }
   ],
   "source": [
    "model = MM_LLMs.from_pretrained(\n",
    "    latest,flash_attention = True, dtype = torch.bfloat16, torch_dtype = torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d90435",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08fdb43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "image_processor = AutoProcessor.from_pretrained('google/siglip-large-patch16-384')\n",
    "tokenizer = AutoTokenizer.from_pretrained(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2279b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def prepare_dataset(messages, images: List[str] = None):\n",
    "    if images is not None:\n",
    "        images = [Image.open(f).convert('RGB') for f in images]\n",
    "        image_output = image_processor(images=images, return_tensors='pt')['pixel_values']\n",
    "    else:\n",
    "        image_output = None\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize = False)\n",
    "    outputs = tokenizer(\n",
    "                    prompt,\n",
    "                    return_tensors='pt',\n",
    "                    return_overflowing_tokens=False,\n",
    "                    return_length=False\n",
    "    )\n",
    "\n",
    "    outputs['images'] = image_output\n",
    "    outputs['image_index'] = torch.tensor([0] * len(outputs['images']))\n",
    "    outputs['image_starts'] = torch.tensor([tokenizer.convert_tokens_to_ids('<image>')] * len(outputs['images']))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb3e6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://cdn.beautifulnara.net/wp-content/uploads/2017/12/10201620/Persian-cat-breed.jpg\n",
    "# !wget https://www.jocooks.com/wp-content/uploads/2023/09/nasi-goreng-1-23.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f479cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = 'translated-LLaVA-Instruct-150K/filtered-llava-images/000000033471.jpg'\n",
    "test_image2 = 'Persian-cat-breed.jpg'\n",
    "test_image3 = 'abang-gay.png'\n",
    "test_image4 = 'nasi-goreng-1-23.jpg'\n",
    "images = [\n",
    "    test_image,\n",
    "    test_image2,\n",
    "    test_image3,\n",
    "    test_image4\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e722b6dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Imej itu menggambarkan bas pelancongan putih yang memandu di jalan bandar yang sibuk. Terdapat beberapa orang di tempat kejadian, dengan seorang berdiri berhampiran tepi jalan dan seorang lagi lebih dekat dengan bas. Beberapa kereta juga boleh dilihat di jalan, termasuk satu di belakang bas dan satu lagi di sebelah kanan.\n",
      "\n",
      "Selain itu, terdapat beberapa lampu isyarat yang kelihatan di sepanjang jalan, dengan satu di sebelah kiri dan satu lagi di sebelah kanan. Kehadiran lampu isyarat menunjukkan bahawa kawasan itu mungkin mempunyai sistem pengurusan trafik yang teratur.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Imej itu adalah gambar hitam putih seekor kucing putih yang cantik dengan mata oren, duduk di atas perabot hitam.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Imej itu menunjukkan seorang lelaki muda berdiri di dalam bilik dengan tingkap, memakai baju hitam dan baju merah. Dia tersenyum dan kelihatan berada di dalam bilik yang gelap.</s>\n",
      "<s>Imej itu memaparkan mangkuk putih yang diisi dengan nasi goreng yang dihiasi dengan lobak merah. Nasi goreng kelihatan rangup dan dihidangkan dengan lobak merah yang dihiris, menjadikannya hidangan yang menarik dan sihat.</s>\n"
     ]
    }
   ],
   "source": [
    "for img in images:\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': '<image> </image> ini gambar apa'},\n",
    "    ]\n",
    "    outputs = prepare_dataset(messages, images = [img])\n",
    "    outputs['images'] = outputs['images'].type(model.dtype)\n",
    "    for k in outputs.keys():\n",
    "        if outputs[k] is not None:\n",
    "            outputs[k] = outputs[k].cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_inputs = model.prepare_inputs_for_generation(**outputs)\n",
    "    r = model_inputs.pop('input_ids', None)\n",
    "\n",
    "    generate_kwargs = dict(\n",
    "        model_inputs,\n",
    "        max_new_tokens=300,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        num_beams=1,\n",
    "    )\n",
    "\n",
    "    r = model.llm.generate(**generate_kwargs)\n",
    "    print(tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8acecaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Tiada hubungan yang jelas antara gambar 1 dan gambar 2. Gambar 1 ialah gambar putih kucing baka kuda, manakala gambar 2 ialah gambar bas bandar di jalan. Satu-satunya sambungan yang mungkin ialah kedua-dua gambar mengandungi unsur-unsur kehidupan seharian: orang dalam gambar 1 dan tempat letak kereta bas bandar dalam gambar 2. Walau bagaimanapun, tiada hubungan khusus antara kedua-dua imej selain itu.</s>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'user', 'content': '<image> </image> <image> </image> apa kaitan 2 gambar ni'},\n",
    "]\n",
    "outputs = prepare_dataset(messages, images = [test_image2, test_image])\n",
    "ok = outputs\n",
    "ok['labels'] = ok['input_ids']\n",
    "\n",
    "for k in ok.keys():\n",
    "    if ok[k] is not None:\n",
    "        ok[k] = ok[k].cuda()\n",
    "        \n",
    "for k in ['images']:\n",
    "    if ok[k] is not None:\n",
    "        ok[k] = ok[k].type(model.dtype)\n",
    "        \n",
    "with torch.no_grad():\n",
    "    model_inputs = model.prepare_inputs_for_generation(**ok)\n",
    "r = model_inputs.pop('input_ids', None)\n",
    "label = model_inputs.pop('labels', None)\n",
    "label = label.detach().cpu().numpy()\n",
    "ok['input_ids'].shape, model_inputs['inputs_embeds'].shape\n",
    "\n",
    "generate_kwargs = dict(\n",
    "    model_inputs,\n",
    "    max_new_tokens=300,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    temperature=0.9,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    ")\n",
    "\n",
    "r = model.llm.generate(**generate_kwargs)\n",
    "print(tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "718c0b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/utils/hub.py:667: UserWarning: The `organization` argument is deprecated and will be removed in v5 of Transformers. Set your organization directly in the `repo_id` passed instead (`repo_id={organization}/{model_id}`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6f51f8c2584cdab1077c84666e2490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-tinyllama-1.1b-siglip-large-384-vision/commit/00e21131e9e67c9304789e18dba0c3a0d5b5e601', commit_message='Upload MM_LLMs', commit_description='', oid='00e21131e9e67c9304789e18dba0c3a0d5b5e601', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('malaysian-tinyllama-1.1b-siglip-large-384-vision', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98862dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/utils/hub.py:667: UserWarning: The `organization` argument is deprecated and will be removed in v5 of Transformers. Set your organization directly in the `repo_id` passed instead (`repo_id={organization}/{model_id}`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbff139e137444596f0db033cd5938f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3739e2b9bd43f78abd2b1cbf8254b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-tinyllama-1.1b-siglip-large-384-vision/commit/50e66426db8e263590229b599c3c3c661327269e', commit_message='Upload processor', commit_description='', oid='50e66426db8e263590229b599c3c3c661327269e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_processor.push_to_hub('malaysian-tinyllama-1.1b-siglip-large-384-vision', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfa9233d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-tinyllama-1.1b-siglip-large-384-vision/commit/55872690f1afafc23e472a715ebf3d50d608969b', commit_message='Upload tokenizer', commit_description='', oid='55872690f1afafc23e472a715ebf3d50d608969b', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub('malaysian-tinyllama-1.1b-siglip-large-384-vision', organization='mesolitica', safe_serialization=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
