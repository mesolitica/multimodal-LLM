{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c05c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 12 05:11:01 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   43C    P0              87W / 400W |  52657MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  | 00000002:00:00.0 Off |                    0 |\n",
      "| N/A   42C    P0             303W / 400W |  73251MiB / 81920MiB |     43%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          On  | 00000003:00:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              87W / 400W |  51225MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          On  | 00000004:00:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              89W / 400W |  53359MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM4-80GB          On  | 0000000B:00:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              94W / 400W |  51153MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM4-80GB          On  | 0000000C:00:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              90W / 400W |  50161MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM4-80GB          On  | 0000000D:00:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              92W / 400W |  58689MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM4-80GB          On  | 0000000E:00:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              88W / 400W |  58797MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6b002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b894f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_vision import MM_LLMs, MM_LLMs_Config\n",
    "from transformers import AutoModelForCausalLM, CLIPProcessor, CLIPModel,AutoModel, AutoTokenizer, AutoProcessor,AutoConfig,CLIPConfig, LlamaConfig, WhisperConfig, WhisperModel, LlamaModel, LlamaTokenizer\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from streaming import LocalDataset\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0161a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "MM_LLMs.register_for_auto_class()\n",
    "MM_LLMs_Config.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9b740b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "latest = get_last_checkpoint('vision-qwen0.5')\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8b6dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    }
   ],
   "source": [
    "model = MM_LLMs.from_pretrained(\n",
    "    latest,flash_attention = True, dtype = torch.bfloat16, torch_dtype = torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45d90435",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08fdb43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "image_processor = AutoProcessor.from_pretrained('google/siglip-base-patch16-384')\n",
    "tokenizer = AutoTokenizer.from_pretrained(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12fa58df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.llm.generation_config.eos_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e2279b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def prepare_dataset(messages, images: List[str] = None):\n",
    "    if images is not None:\n",
    "        images = [Image.open(f).convert('RGB') for f in images]\n",
    "        image_output = image_processor(images=images, return_tensors='pt')['pixel_values']\n",
    "    else:\n",
    "        image_output = None\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize = False)\n",
    "    outputs = tokenizer(\n",
    "                    prompt,\n",
    "                    return_tensors='pt',\n",
    "                    return_overflowing_tokens=False,\n",
    "                    return_length=False\n",
    "    )\n",
    "\n",
    "    outputs['images'] = image_output\n",
    "    outputs['image_index'] = torch.tensor([0] * len(outputs['images']))\n",
    "    outputs['image_starts'] = torch.tensor([tokenizer.convert_tokens_to_ids('<image>')] * len(outputs['images']))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb3e6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://cdn.beautifulnara.net/wp-content/uploads/2017/12/10201620/Persian-cat-breed.jpg\n",
    "# !wget https://www.jocooks.com/wp-content/uploads/2023/09/nasi-goreng-1-23.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f479cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = 'translated-LLaVA-Instruct-150K/filtered-llava-images/000000033471.jpg'\n",
    "test_image2 = 'Persian-cat-breed.jpg'\n",
    "test_image3 = 'abang-gay.png'\n",
    "test_image4 = 'nasi-goreng-1-23.jpg'\n",
    "images = [\n",
    "    test_image,\n",
    "    test_image2,\n",
    "    test_image3,\n",
    "    test_image4\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e722b6dd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|><|im_start|>assistant\n",
      "Ini adalah gambar bas dua tingkat yang diletakkan di jalan bandar.<|im_end|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|><|im_start|>assistant\n",
      "Ini adalah gambar kucing putih yang duduk di atas sofa hitam.<|im_end|>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|><|im_start|>assistant\n",
      "Imej itu menampilkan seorang lelaki berambut panjang berdiri di hadapan meja dengan beg galas di tangannya. Dia tersenyum dan tersenyum, menunjukkan bahawa dia gembira atau berpuas hati. Lelaki itu memakai baju hitam dan seluar pendek merah, yang menambahkan lagi suasana positifnya.<|im_end|>\n",
      "<|endoftext|><|im_start|>assistant\n",
      "Imej ini menampilkan mangkuk putih yang diisi dengan pelbagai bahan, termasuk mi, sayur-sayuran, dan bahan-bahan lain. Terdapat beberapa lobak merah yang tersebar di seluruh mangkuk, menambah warna dan tekstur pada hidangan. Selain itu, terdapat sudu yang diletakkan di atas mangkuk, mungkin untuk menghidangkan hidangan.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "for img in images:\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': '<image> </image> ini gambar apa'},\n",
    "    ]\n",
    "    outputs = prepare_dataset(messages, images = [img])\n",
    "    outputs['images'] = outputs['images'].type(model.dtype)\n",
    "    for k in outputs.keys():\n",
    "        if outputs[k] is not None:\n",
    "            outputs[k] = outputs[k].cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_inputs = model.prepare_inputs_for_generation(**outputs)\n",
    "    r = model_inputs.pop('input_ids', None)\n",
    "\n",
    "    generate_kwargs = dict(\n",
    "        model_inputs,\n",
    "        max_new_tokens=300,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        num_beams=1,\n",
    "    )\n",
    "\n",
    "    r = model.llm.generate(**generate_kwargs)\n",
    "    print(tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8acecaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|><|im_start|>assistant\n",
      "Tiada hubungan langsung antara gambar 1 dan gambar 2. Gambar 1 ialah imej kucing putih dengan bulu putih, manakala gambar 2 ialah gambar mangkuk makan tengah hari kacang hitam dan lobak merah yang dicincang, dengan garpu diletakkan di sebelahnya. Kedua-duanya tidak berkaitan dari segi kandungan.<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'user', 'content': '<image> </image> <image> </image> apa kaitan 2 gambar ni'},\n",
    "]\n",
    "outputs = prepare_dataset(messages, images = [test_image2, test_image4])\n",
    "outputs['images'] = outputs['images'].type(model.dtype)\n",
    "for k in outputs.keys():\n",
    "    if outputs[k] is not None:\n",
    "        outputs[k] = outputs[k].cuda()\n",
    "        \n",
    "with torch.no_grad():\n",
    "    model_inputs = model.prepare_inputs_for_generation(**outputs)\n",
    "r = model_inputs.pop('input_ids', None)\n",
    "label = model_inputs.pop('labels', None)\n",
    "outputs['input_ids'].shape, model_inputs['inputs_embeds'].shape\n",
    "\n",
    "generate_kwargs = dict(\n",
    "    model_inputs,\n",
    "    max_new_tokens=300,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    temperature=0.9,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    ")\n",
    "\n",
    "r = model.llm.generate(**generate_kwargs)\n",
    "print(tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub('malaysian-Qwen1.5-0.5B-siglip-base-384-vision', organization='mesolitica', safe_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98862dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor.push_to_hub('malaysian-Qwen1.5-0.5B-siglip-base-384-vision', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa9233d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub('malaysian-Qwen1.5-0.5B-siglip-base-384-vision', organization='mesolitica', safe_serialization=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
