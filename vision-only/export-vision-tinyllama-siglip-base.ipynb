{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c05c697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Feb 11 15:46:57 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   40C    P0              73W / 400W |  28507MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  | 00000002:00:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              86W / 400W |  77915MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          On  | 00000003:00:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              82W / 400W |  63541MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          On  | 00000004:00:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              83W / 400W |  35157MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM4-80GB          On  | 0000000B:00:00.0 Off |                    0 |\n",
      "| N/A   41C    P0              89W / 400W |  33759MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM4-80GB          On  | 0000000C:00:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              83W / 400W |  33321MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM4-80GB          On  | 0000000D:00:00.0 Off |                    0 |\n",
      "| N/A   42C    P0              87W / 400W |  49231MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM4-80GB          On  | 0000000E:00:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              81W / 400W |  29117MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6b002d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b894f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_vision import MM_LLMs, MM_LLMs_Config\n",
    "from transformers import AutoModelForCausalLM, CLIPProcessor, CLIPModel,AutoModel, AutoTokenizer, AutoProcessor,AutoConfig,CLIPConfig, LlamaConfig, WhisperConfig, WhisperModel, LlamaModel, LlamaTokenizer\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from streaming import LocalDataset\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0161a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "MM_LLMs.register_for_auto_class()\n",
    "MM_LLMs_Config.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9b740b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vision-tinyllama/checkpoint-3750'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "latest = get_last_checkpoint('vision-tinyllama')\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b6dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    }
   ],
   "source": [
    "model = MM_LLMs.from_pretrained(\n",
    "    latest,flash_attention = True, dtype = torch.bfloat16, torch_dtype = torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45d90435",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08fdb43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "image_processor = AutoProcessor.from_pretrained('google/siglip-base-patch16-384')\n",
    "tokenizer = AutoTokenizer.from_pretrained(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e2279b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def prepare_dataset(messages, images: List[str] = None):\n",
    "    if images is not None:\n",
    "        images = [Image.open(f).convert('RGB') for f in images]\n",
    "        image_output = image_processor(images=images, return_tensors='pt')['pixel_values']\n",
    "    else:\n",
    "        image_output = None\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize = False)\n",
    "    outputs = tokenizer(\n",
    "                    prompt,\n",
    "                    return_tensors='pt',\n",
    "                    return_overflowing_tokens=False,\n",
    "                    return_length=False\n",
    "    )\n",
    "\n",
    "    outputs['images'] = image_output\n",
    "    outputs['image_index'] = torch.tensor([0] * len(outputs['images']))\n",
    "    outputs['image_starts'] = torch.tensor([tokenizer.convert_tokens_to_ids('<image>')] * len(outputs['images']))\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb3e6b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://cdn.beautifulnara.net/wp-content/uploads/2017/12/10201620/Persian-cat-breed.jpg\n",
    "# !wget https://www.jocooks.com/wp-content/uploads/2023/09/nasi-goreng-1-23.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f479cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = 'translated-LLaVA-Instruct-150K/filtered-llava-images/000000033471.jpg'\n",
    "test_image2 = 'Persian-cat-breed.jpg'\n",
    "test_image3 = 'abang-gay.png'\n",
    "test_image4 = 'nasi-goreng-1-23.jpg'\n",
    "images = [\n",
    "    test_image,\n",
    "    test_image2,\n",
    "    test_image3,\n",
    "    test_image4\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e722b6dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Imej itu menunjukkan bas penumpang putih yang besar di jalan bandar yang sibuk. Bas itu mempunyai iklan yang dipaparkan di sisinya, menarik perhatian kepada perkhidmatan pengangkutan yang ditawarkannya.\n",
      "\n",
      "Di sekeliling bas, terdapat beberapa kereta dan trak yang diletakkan atau memandu di jalan. Terdapat juga beberapa orang yang kelihatan di tempat kejadian, ada yang berjalan dan yang lain berdiri atau duduk di kaki lima. Selain itu, terdapat dua beg tangan yang kelihatan di tempat kejadian, mungkin milik orang yang berjalan atau diletakkan di kaki lima.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Imej itu menampilkan kucing putih yang terletak di atas sofa hitam.</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Imej itu menunjukkan seorang lelaki muda berdiri di hadapan tingkap, tersenyum dan kelihatan gembira. Dia memakai baju polo hitam dan mempunyai beg galas di sebelahnya.</s>\n",
      "<s>Imej ini menampilkan mangkuk putih yang diisi dengan nasi dan pelbagai jenis makanan, termasuk lobak merah dan kacang hijau. Mangkuk itu diletakkan di atas meja, menunjukkan bahawa ia sedia untuk dimakan.</s>\n"
     ]
    }
   ],
   "source": [
    "for img in images:\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': '<image> </image> ini gambar apa'},\n",
    "    ]\n",
    "    outputs = prepare_dataset(messages, images = [img])\n",
    "    outputs['images'] = outputs['images'].type(model.dtype)\n",
    "    for k in outputs.keys():\n",
    "        if outputs[k] is not None:\n",
    "            outputs[k] = outputs[k].cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model_inputs = model.prepare_inputs_for_generation(**outputs)\n",
    "    r = model_inputs.pop('input_ids', None)\n",
    "\n",
    "    generate_kwargs = dict(\n",
    "        model_inputs,\n",
    "        max_new_tokens=300,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        temperature=0.1,\n",
    "        do_sample=True,\n",
    "        num_beams=1,\n",
    "    )\n",
    "\n",
    "    r = model.llm.generate(**generate_kwargs)\n",
    "    print(tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8acecaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Tiada hubungan langsung antara gambar 1 dan gambar 2. Gambar 1 ialah imej Anjing Kucing Perang putih, manakala gambar 2 ialah imej semangkuk nasi goreng dengan nasi, ayam dan bawang hijau. Kedua-dua imej itu tidak mempunyai sebarang elemen atau konteks yang sama.</s>\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'user', 'content': '<image> </image> <image> </image> apa kaitan 2 gambar ni'},\n",
    "]\n",
    "outputs = prepare_dataset(messages, images = [test_image2, test_image4])\n",
    "ok = outputs\n",
    "ok['labels'] = ok['input_ids']\n",
    "\n",
    "for k in ok.keys():\n",
    "    if ok[k] is not None:\n",
    "        ok[k] = ok[k].cuda()\n",
    "        \n",
    "for k in ['images']:\n",
    "    if ok[k] is not None:\n",
    "        ok[k] = ok[k].type(model.dtype)\n",
    "        \n",
    "with torch.no_grad():\n",
    "    model_inputs = model.prepare_inputs_for_generation(**ok)\n",
    "r = model_inputs.pop('input_ids', None)\n",
    "label = model_inputs.pop('labels', None)\n",
    "label = label.detach().cpu().numpy()\n",
    "ok['input_ids'].shape, model_inputs['inputs_embeds'].shape\n",
    "\n",
    "generate_kwargs = dict(\n",
    "    model_inputs,\n",
    "    max_new_tokens=300,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    temperature=0.9,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    ")\n",
    "\n",
    "r = model.llm.generate(**generate_kwargs)\n",
    "print(tokenizer.decode(r[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a76c8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<s>Ya, abang kelihatan gay dalam gambar.</s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'user', 'content': '<image> </image> abang ni nampak gay tak'},\n",
    "]\n",
    "outputs = prepare_dataset(messages, images = [test_image3])\n",
    "ok = outputs\n",
    "ok['labels'] = ok['input_ids']\n",
    "\n",
    "for k in ok.keys():\n",
    "    if ok[k] is not None:\n",
    "        ok[k] = ok[k].cuda()\n",
    "        \n",
    "for k in ['images']:\n",
    "    if ok[k] is not None:\n",
    "        ok[k] = ok[k].type(model.dtype)\n",
    "        \n",
    "with torch.no_grad():\n",
    "    model_inputs = model.prepare_inputs_for_generation(**ok)\n",
    "r = model_inputs.pop('input_ids', None)\n",
    "label = model_inputs.pop('labels', None)\n",
    "label = label.detach().cpu().numpy()\n",
    "ok['input_ids'].shape, model_inputs['inputs_embeds'].shape\n",
    "\n",
    "generate_kwargs = dict(\n",
    "    model_inputs,\n",
    "    max_new_tokens=300,\n",
    "    top_p=0.95,\n",
    "    top_k=50,\n",
    "    temperature=0.1,\n",
    "    do_sample=True,\n",
    "    num_beams=1,\n",
    ")\n",
    "\n",
    "r = model.llm.generate(**generate_kwargs)\n",
    "tokenizer.decode(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ac3fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image.open('abang-gay.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "718c0b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/utils/hub.py:667: UserWarning: The `organization` argument is deprecated and will be removed in v5 of Transformers. Set your organization directly in the `repo_id` passed instead (`repo_id={organization}/{model_id}`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad35ab4ced844bda80e51ccd4fb91bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32d6f6c56fee4f7b930699381ea36b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-tinyllama-1.1b-siglip-base-384-vision/commit/cbf6d2c42ed988c80d003e0f5eba47e495dcf44c', commit_message='Upload MM_LLMs', commit_description='', oid='cbf6d2c42ed988c80d003e0f5eba47e495dcf44c', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('malaysian-tinyllama-1.1b-siglip-base-384-vision', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98862dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/utils/hub.py:667: UserWarning: The `organization` argument is deprecated and will be removed in v5 of Transformers. Set your organization directly in the `repo_id` passed instead (`repo_id={organization}/{model_id}`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-tinyllama-1.1b-siglip-base-384-vision/commit/da0d3d9a93b795f21c010e3e99b952767e3aaa48', commit_message='Upload processor', commit_description='', oid='da0d3d9a93b795f21c010e3e99b952767e3aaa48', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_processor.push_to_hub('malaysian-tinyllama-1.1b-siglip-base-384-vision', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfa9233d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-tinyllama-1.1b-siglip-base-384-vision/commit/a338232c994d7a40e0aa89f5285034cdbdf65d6e', commit_message='Upload tokenizer', commit_description='', oid='a338232c994d7a40e0aa89f5285034cdbdf65d6e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub('malaysian-tinyllama-1.1b-siglip-base-384-vision', organization='mesolitica', safe_serialization=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
