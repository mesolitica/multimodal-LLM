{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb41da79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from typing import Mapping, List, Dict\n",
    "from datasets import Audio\n",
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "from streaming import LocalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced99020",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollator():\n",
    "\n",
    "    def __init__(self, tokenizer):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, features):\n",
    "\n",
    "        features = [f for f in features if f is not None]\n",
    "\n",
    "        if not isinstance(features[0], Mapping):\n",
    "            features = [vars(f) for f in features]\n",
    "\n",
    "        batch = {}\n",
    "        bs = len(features)\n",
    "        first = features[0]\n",
    "\n",
    "        batch['audio_index'] = torch.tensor([], dtype=torch.int)\n",
    "        batch['image_index'] = torch.tensor([], dtype=torch.int)\n",
    "\n",
    "        for index, feature in enumerate(features):\n",
    "            local_index = index % (bs)\n",
    "\n",
    "            if feature['audios_bool'][0] and feature['audios'] is not None:\n",
    "                batch['audio_index'] = torch.cat([batch['audio_index'], torch.tensor(\n",
    "                    [local_index] * len(feature['audios']), dtype=torch.int)])\n",
    "\n",
    "            if feature['images_bool'][0] and feature['images'] is not None:\n",
    "                batch['image_index'] = torch.cat([batch['image_index'], torch.tensor(\n",
    "                    [local_index] * len(feature['images']), dtype=torch.int)])\n",
    "\n",
    "        for k, v in first.items():\n",
    "\n",
    "            if k not in (\n",
    "                    \"audios\",\n",
    "                    \"images\",\n",
    "                    \"input_ids\",\n",
    "                    \"attention_mask\"\n",
    "            ) and not isinstance(v, str):\n",
    "                if v is None:\n",
    "                    batch[k] = None\n",
    "                elif isinstance(v, torch.Tensor):\n",
    "                    batch[k] = torch.stack([f[k] for f in features]).squeeze(1)\n",
    "                elif isinstance(v, np.ndarray):\n",
    "                    batch[k] = torch.tensor(np.stack([f[k] for f in features])).squeeze(1)\n",
    "            elif k in (\"audios\", \"images\"):\n",
    "                if v is None:\n",
    "                    batch[k] = None\n",
    "                else:\n",
    "                    batch[k] = torch.cat([f[k] for f in features if f[k] is not None])\n",
    "\n",
    "        input_ids = [{'input_ids': f['input_ids'][0]} for f in features]\n",
    "        input_ids = self.tokenizer.pad(input_ids)\n",
    "        batch['input_ids'] = input_ids['input_ids']\n",
    "        batch['attention_mask'] = input_ids['attention_mask']\n",
    "        batch['labels'] = input_ids['input_ids'].clone()\n",
    "        batch['labels'][batch['labels'] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        image_token = self.tokenizer.convert_tokens_to_ids('<image>')\n",
    "        image_end_token = self.tokenizer.convert_tokens_to_ids('</image>')\n",
    "        audio_token = self.tokenizer.convert_tokens_to_ids('<audio>')\n",
    "        audio_end_token = self.tokenizer.convert_tokens_to_ids('</audio>')\n",
    "\n",
    "        batch['image_starts'] = torch.tensor([image_token] * bs, dtype=torch.int)\n",
    "        batch['image_ends'] = torch.tensor([image_end_token] * bs, dtype=torch.int)\n",
    "        batch['audio_starts'] = torch.tensor([audio_token] * bs, dtype=torch.int)\n",
    "        batch['audio_ends'] = torch.tensor([audio_end_token] * bs, dtype=torch.int)\n",
    "\n",
    "        where_is = torch.where((batch['input_ids'] == image_token) | (batch['input_ids'] == audio_token))\n",
    "        ls = []\n",
    "        for i in range(len(where_is[0])):\n",
    "            b, k = where_is[0][i], where_is[1][i]\n",
    "            l = int(batch['input_ids'][b, k])\n",
    "            ls.append(l)\n",
    "\n",
    "        ls = torch.tensor(ls)\n",
    "        batch['where_is_b'] = where_is[0]\n",
    "        batch['where_is_k'] = where_is[1]\n",
    "        batch['ls'] = ls\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5815737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./combine-tinyllama')\n",
    "tokenizer.add_tokens([\"<image>\", \"</image>\", \"<audio>\", \"</audio>\"])\n",
    "max_length = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33480132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "image_processor = AutoProcessor.from_pretrained('google/siglip-base-patch16-384')\n",
    "default_height = image_processor.image_processor.size['height']\n",
    "audio_processor = AutoProcessor.from_pretrained('mesolitica/malaysian-whisper-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5870390",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListOfDict(Encoding):\n",
    "    def encode(self, obj: List[dict]) -> bytes:\n",
    "        json_str = json.dumps(obj)\n",
    "        return json_str.encode('utf-8')\n",
    "\n",
    "    def decode(self, data: bytes) -> List[dict]:\n",
    "        json_str = data.decode('utf-8')\n",
    "        return json.loads(json_str)\n",
    "\n",
    "_encodings['list_of_dict'] = ListOfDict\n",
    "\n",
    "class MMDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, folder):\n",
    "        if folder.endswith('.json'):\n",
    "            with open(folder) as fopen:\n",
    "                self.dataset = json.load(fopen)\n",
    "        else:\n",
    "            self.dataset = LocalDataset(folder)\n",
    "\n",
    "        self.sr = 16000\n",
    "        self.audio = Audio(sampling_rate=self.sr)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            data = self.dataset[idx]\n",
    "            \n",
    "            audio = np.zeros((self.sr * 10,))\n",
    "            audio_features = audio_processor(audio, sampling_rate=self.sr, return_tensors='pt')\n",
    "            audio_list = [audio_features['input_features']]\n",
    "            audio_bool = [True]\n",
    "\n",
    "            image = np.zeros((3, default_height, default_height))\n",
    "\n",
    "            image_output = image_processor(\n",
    "                images=image, return_tensors='pt')['pixel_values']\n",
    "            image_list = [image_output]\n",
    "            image_bool = [True] \n",
    "\n",
    "            for x in data['filename']:\n",
    "                if x.endswith('.mp3'):\n",
    "                    audio = self.audio.decode_example(self.audio.encode_example(x))['array']\n",
    "\n",
    "                    audio_features = audio_processor(\n",
    "                        audio, sampling_rate=self.sr, return_tensors='pt')\n",
    "\n",
    "                    audio_list.append(audio_features['input_features'])\n",
    "                    audio_bool.append(True)\n",
    "\n",
    "                elif x.endswith('.jpg'):\n",
    "                    image = Image.open(x).convert('RGB')\n",
    "\n",
    "                    image_output = image_processor(\n",
    "                        images=image, return_tensors='pt')['pixel_values']\n",
    "\n",
    "                    image_list.append(image_output)\n",
    "                    image_bool.append(True)\n",
    "\n",
    "            full_text = tokenizer.apply_chat_template(data['conversations'], tokenize=False)\n",
    "            full_text = f'<image> <audio> {full_text}'\n",
    "\n",
    "            outputs = tokenizer(\n",
    "                full_text,\n",
    "                return_tensors='pt',\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                return_overflowing_tokens=False,\n",
    "                return_length=False\n",
    "            )\n",
    "\n",
    "            outputs['audios'] = torch.cat(audio_list, dim=0) if audio_list else None\n",
    "            outputs['images'] = torch.cat(image_list, dim=0) if image_list else None\n",
    "            outputs['audios_bool'] = audio_bool\n",
    "            outputs['images_bool'] = image_bool\n",
    "\n",
    "            return outputs\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfb2db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MMDataset('mosaic-multimodal')\n",
    "data_collator = DataCollator(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bf37f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "ranged = list(range(len(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d889d08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "b = [train_dataset[random.choice(ranged)] for i in range(10)]\n",
    "input_ids = data_collator(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c36256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.8 s, sys: 74.3 ms, total: 38.9 s\n",
      "Wall time: 473 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_ids = data_collator(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b5db1b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio_index': tensor([0, 1, 2, 2, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9], dtype=torch.int32),\n",
       " 'image_index': tensor([0, 0, 0, 1, 1, 2, 3, 3, 3, 4, 5, 5, 6, 7, 8, 9], dtype=torch.int32),\n",
       " 'audios': tensor([[[-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          ...,\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000]],\n",
       " \n",
       "         [[-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          ...,\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000]],\n",
       " \n",
       "         [[-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          ...,\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 0.2761,  0.7912,  0.6083,  ...,  0.4361,  0.3640,  0.2981],\n",
       "          [ 0.7858,  0.6548,  0.4699,  ...,  0.3221,  0.2849,  0.2621],\n",
       "          [ 0.9925,  0.8057,  0.7724,  ...,  0.1139,  0.0806,  0.1188],\n",
       "          ...,\n",
       "          [-0.2553, -0.1687, -0.1764,  ..., -0.2301, -0.3035, -0.2417],\n",
       "          [-0.2925, -0.4122, -0.4064,  ..., -0.5799, -0.5287, -0.4500],\n",
       "          [-0.4383, -0.6885, -0.6885,  ..., -0.6885, -0.6885, -0.6885]],\n",
       " \n",
       "         [[-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          ...,\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000],\n",
       "          [-1.5000, -1.5000, -1.5000,  ..., -1.5000, -1.5000, -1.5000]],\n",
       " \n",
       "         [[ 1.1710,  0.7069,  1.1279,  ...,  0.2260,  0.2142,  0.0888],\n",
       "          [ 1.1877,  1.1196,  1.1948,  ...,  0.4490,  0.2912,  0.4202],\n",
       "          [ 1.0371,  1.0672,  1.0853,  ...,  0.4068,  0.3786,  0.5083],\n",
       "          ...,\n",
       "          [ 0.1695, -0.0547, -0.0743,  ..., -0.4097, -0.1676, -0.0341],\n",
       "          [ 0.2237, -0.1969, -0.2746,  ..., -0.6120, -0.2649, -0.1311],\n",
       "          [ 0.1974, -0.3137, -0.6120,  ..., -0.6120, -0.6120, -0.6120]]]),\n",
       " 'images': tensor([[[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       " \n",
       "          [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       " \n",
       "          [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0588,  0.0824,  0.1529,  ..., -0.3569, -0.0980,  0.0588],\n",
       "           [ 0.4588,  0.4196,  0.4196,  ..., -0.5843, -0.4745, -0.4039],\n",
       "           [ 0.2235,  0.1765,  0.1608,  ..., -0.5059, -0.5451, -0.5608],\n",
       "           ...,\n",
       "           [-0.6863, -0.6941, -0.6627,  ..., -0.7333, -0.7098, -0.6941],\n",
       "           [-0.7490, -0.7333, -0.6706,  ..., -0.7098, -0.6706, -0.6784],\n",
       "           [-0.8039, -0.7333, -0.6392,  ..., -0.7098, -0.6627, -0.7020]],\n",
       " \n",
       "          [[-0.0118,  0.0118,  0.0745,  ..., -0.3490, -0.0902,  0.0667],\n",
       "           [ 0.3882,  0.3490,  0.3412,  ..., -0.5765, -0.4667, -0.3961],\n",
       "           [ 0.1451,  0.1059,  0.0745,  ..., -0.4980, -0.5373, -0.5529],\n",
       "           ...,\n",
       "           [-0.7255, -0.7333, -0.7020,  ..., -0.7333, -0.7176, -0.7020],\n",
       "           [-0.7882, -0.7725, -0.7098,  ..., -0.7020, -0.6627, -0.6706],\n",
       "           [-0.8431, -0.7725, -0.6784,  ..., -0.7020, -0.6549, -0.6941]],\n",
       " \n",
       "          [[ 0.0118,  0.0353,  0.0980,  ..., -0.3882, -0.1294,  0.0275],\n",
       "           [ 0.4118,  0.3804,  0.3647,  ..., -0.6157, -0.5059, -0.4353],\n",
       "           [ 0.1529,  0.1137,  0.0902,  ..., -0.5373, -0.5765, -0.5922],\n",
       "           ...,\n",
       "           [-0.6784, -0.6863, -0.6549,  ..., -0.7020, -0.6784, -0.6627],\n",
       "           [-0.7412, -0.7255, -0.6627,  ..., -0.6863, -0.6471, -0.6549],\n",
       "           [-0.7961, -0.7255, -0.6314,  ..., -0.6863, -0.6392, -0.6784]]],\n",
       " \n",
       " \n",
       "         [[[-0.9529, -0.9529, -0.9608,  ..., -0.4196, -0.4118, -0.2000],\n",
       "           [-0.9294, -0.9373, -0.9451,  ..., -0.4353, -0.4039, -0.1922],\n",
       "           [-0.9294, -0.9294, -0.9216,  ..., -0.4275, -0.4118, -0.2078],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -0.9922,  ..., -0.2392, -0.2314, -0.2314],\n",
       "           [-1.0000, -0.9922, -1.0000,  ..., -0.2314, -0.2314, -0.2314],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -0.2314, -0.2314, -0.2314]],\n",
       " \n",
       "          [[-0.9686, -0.9686, -0.9765,  ..., -0.2078, -0.2314, -0.0510],\n",
       "           [-0.9686, -0.9765, -0.9765,  ..., -0.2235, -0.2235, -0.0431],\n",
       "           [-0.9922, -0.9843, -0.9922,  ..., -0.2157, -0.2314, -0.0510],\n",
       "           ...,\n",
       "           [-0.0196, -0.0118, -0.0039,  ..., -0.2392, -0.2314, -0.2314],\n",
       "           [-0.0039,  0.0039,  0.0039,  ..., -0.2314, -0.2314, -0.2314],\n",
       "           [-0.0039, -0.0039,  0.0039,  ..., -0.2314, -0.2314, -0.2314]],\n",
       " \n",
       "          [[-0.9451, -0.9451, -0.9529,  ..., -0.0510, -0.1686, -0.0196],\n",
       "           [-0.9373, -0.9451, -0.9451,  ..., -0.0824, -0.1608, -0.0118],\n",
       "           [-0.9608, -0.9608, -0.9608,  ..., -0.1294, -0.1843, -0.0353],\n",
       "           ...,\n",
       "           [ 0.8431,  0.8510,  0.8667,  ..., -0.3020, -0.3098, -0.3098],\n",
       "           [ 0.8353,  0.8431,  0.8588,  ..., -0.2941, -0.3098, -0.3098],\n",
       "           [ 0.8353,  0.8353,  0.8588,  ..., -0.2941, -0.3098, -0.3098]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       " \n",
       "          [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       " \n",
       "          [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
       " \n",
       " \n",
       "         [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       " \n",
       "          [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       " \n",
       "          [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]],\n",
       " \n",
       " \n",
       "         [[[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       " \n",
       "          [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]],\n",
       " \n",
       "          [[-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           ...,\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000],\n",
       "           [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -1.0000]]]]),\n",
       " 'input_ids': tensor([[32000, 32002, 29871,  ...,     0,     0,     0],\n",
       "         [32000, 32002, 29871,  ...,     0,     0,     0],\n",
       "         [32000, 32002, 29871,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [32000, 32002, 29871,  ...,     0,     0,     0],\n",
       "         [32000, 32002, 29871,  ...,     0,     0,     0],\n",
       "         [32000, 32002, 29871,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([[32000, 32002, 29871,  ...,  -100,  -100,  -100],\n",
       "         [32000, 32002, 29871,  ...,  -100,  -100,  -100],\n",
       "         [32000, 32002, 29871,  ...,  -100,  -100,  -100],\n",
       "         ...,\n",
       "         [32000, 32002, 29871,  ...,  -100,  -100,  -100],\n",
       "         [32000, 32002, 29871,  ...,  -100,  -100,  -100],\n",
       "         [32000, 32002, 29871,  ...,  -100,  -100,  -100]]),\n",
       " 'image_starts': tensor([32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000, 32000],\n",
       "        dtype=torch.int32),\n",
       " 'image_ends': tensor([32001, 32001, 32001, 32001, 32001, 32001, 32001, 32001, 32001, 32001],\n",
       "        dtype=torch.int32),\n",
       " 'audio_starts': tensor([32002, 32002, 32002, 32002, 32002, 32002, 32002, 32002, 32002, 32002],\n",
       "        dtype=torch.int32),\n",
       " 'audio_ends': tensor([32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003, 32003],\n",
       "        dtype=torch.int32),\n",
       " 'where_is_b': tensor([0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6,\n",
       "         7, 7, 7, 8, 8, 8, 9, 9, 9]),\n",
       " 'where_is_k': tensor([0, 1, 7, 9, 0, 1, 7, 0, 1, 7, 0, 1, 7, 9, 0, 1, 7, 0, 1, 7, 9, 0, 1, 7,\n",
       "         0, 1, 7, 0, 1, 7, 0, 1, 7]),\n",
       " 'ls': tensor([32000, 32002, 32000, 32000, 32000, 32002, 32000, 32000, 32002, 32002,\n",
       "         32000, 32002, 32000, 32000, 32000, 32002, 32002, 32000, 32002, 32002,\n",
       "         32000, 32000, 32002, 32002, 32000, 32002, 32002, 32000, 32002, 32002,\n",
       "         32000, 32002, 32002])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23ca49a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_combine import MM_LLMs, MM_LLMs_Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36877aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83390c5757f145438b2fdb6a9332cd36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MM_LLMs.from_pretrained('./combine-tinyllama')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d07e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = model.prepare_inputs_for_generation(**input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d5a0828",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 29871, 1, 518, 25580, 29962, 32000, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "print(r['labels'][0].numpy().tolist()[:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8c2d7f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29871,     1,   518, 25580, 29962, 32000, 32001, 32000, 32001,  1724,\n",
       "          338,  4475,  1546,  7623, 29871, 29896,   322,  7623, 29871, 29906,\n",
       "          518, 29914, 25580, 29962,  3112,   338, 25057,   393,   727,   338,\n",
       "          263,  1513,  9443,  1546,  7623, 29871, 29896,   322,  7623, 29871,\n",
       "        29906, 29889, 28908, 29871, 29896,   338,   385,  1967,   310,   263,\n",
       "        16423,  6492,  1754,   411,   380,  7358, 29892,  1550,  7623, 29871,\n",
       "        29906,  3697,  1023,  5648,  9763,  1634,   272,  2153, 13587,  2723,\n",
       "          567,  1550,  9963, 29889,  3118,  1950,  3957,  1033,   367,   393,\n",
       "          278, 16423,  6492,   297,  7623, 29871, 29896,   338,  1641, 15000,\n",
       "          297,   263,  9763,  3461, 29892,   322,   278,  1634,   272,  2153,\n",
       "          297,  7623, 29871, 29906,   526,  5353,   292,   372, 29889,  2398,\n",
       "        29892,  1728,  5684,  3030, 29892,   445,   338,   925,  1580,  2785,\n",
       "        29889,     2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r['labels'][0][r['labels'][0] != -100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ffd9e09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> [INST]<image></image><image></image> What is related between picture 1 and picture 2 [/INST]It is unlikely that there is a direct relationship between picture 1 and picture 2. Picture 1 is an image of a garden plot made with sticks, while picture 2 shows two TV news reporters holding cups while talking. One possible connection could be that the garden plot in picture 1 is being featured in a news report, and the reporters in picture 2 are discussing it. However, without additional context, this is just speculation.</s>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(r['labels'][0][r['labels'][0] != -100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3875024",
   "metadata": {},
   "outputs": [],
   "source": [
    "r['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3143a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "r['inputs_embeds'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9492169d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(r['attention_mask'][0].numpy().tolist()[:1100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c02c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r['labels'] == -100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
