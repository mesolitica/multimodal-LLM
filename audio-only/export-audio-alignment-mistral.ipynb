{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c05c697",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 15 16:44:28 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000001:00:00.0 Off |                    0 |\n",
      "| N/A   58C    P0             267W / 400W |  45485MiB / 81920MiB |     99%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  | 00000002:00:00.0 Off |                    0 |\n",
      "| N/A   51C    P0             317W / 400W |  66143MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          On  | 00000003:00:00.0 Off |                    0 |\n",
      "| N/A   55C    P0             395W / 400W |  42127MiB / 81920MiB |     99%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          On  | 00000004:00:00.0 Off |                    0 |\n",
      "| N/A   53C    P0             311W / 400W |  68571MiB / 81920MiB |     99%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA A100-SXM4-80GB          On  | 0000000B:00:00.0 Off |                    0 |\n",
      "| N/A   57C    P0             342W / 400W |  59703MiB / 81920MiB |    100%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA A100-SXM4-80GB          On  | 0000000C:00:00.0 Off |                    0 |\n",
      "| N/A   53C    P0             369W / 400W |  40055MiB / 81920MiB |     99%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA A100-SXM4-80GB          On  | 0000000D:00:00.0 Off |                    0 |\n",
      "| N/A   58C    P0             341W / 400W |  80813MiB / 81920MiB |     99%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA A100-SXM4-80GB          On  | 0000000E:00:00.0 Off |                    0 |\n",
      "| N/A   55C    P0             241W / 400W |  60665MiB / 81920MiB |     99%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c66e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b894f8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modeling_audio import MM_LLMs, MM_LLMs_Config\n",
    "from transformers import AutoModelForCausalLM, CLIPProcessor, CLIPModel,AutoModel, AutoTokenizer, AutoProcessor,AutoConfig,CLIPConfig, LlamaConfig, WhisperConfig, WhisperModel, LlamaModel, LlamaTokenizer\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from streaming import LocalDataset\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe74f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "MM_LLMs.register_for_auto_class()\n",
    "MM_LLMs_Config.register_for_auto_class()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9b740b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'audio-alignment-mistral/checkpoint-7800'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "\n",
    "latest = get_last_checkpoint('audio-alignment-mistral')\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8b6dd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b41bb68c5cf2470392e8ecae5611e93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = MM_LLMs.from_pretrained(\n",
    "    latest,flash_attention = True, dtype = torch.bfloat16, torch_dtype = torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727c03bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MM_LLMs_Config {\n",
       "  \"_name_or_path\": \"audio-alignment-mistral/checkpoint-7800\",\n",
       "  \"architectures\": [\n",
       "    \"MM_LLMs\"\n",
       "  ],\n",
       "  \"audio_config\": {\n",
       "    \"_name_or_path\": \"mesolitica/malaysian-whisper-small\",\n",
       "    \"activation_dropout\": 0.0,\n",
       "    \"activation_function\": \"gelu\",\n",
       "    \"add_cross_attention\": false,\n",
       "    \"apply_spec_augment\": false,\n",
       "    \"architectures\": [\n",
       "      \"WhisperForConditionalGeneration\"\n",
       "    ],\n",
       "    \"attention_dropout\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": [\n",
       "      220,\n",
       "      50257\n",
       "    ],\n",
       "    \"bos_token_id\": 50257,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"classifier_proj_size\": 256,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"d_model\": 768,\n",
       "    \"decoder_attention_heads\": 12,\n",
       "    \"decoder_ffn_dim\": 3072,\n",
       "    \"decoder_layerdrop\": 0.0,\n",
       "    \"decoder_layers\": 12,\n",
       "    \"decoder_start_token_id\": 50258,\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"dropout\": 0.0,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_attention_heads\": 12,\n",
       "    \"encoder_ffn_dim\": 3072,\n",
       "    \"encoder_layerdrop\": 0.0,\n",
       "    \"encoder_layers\": 12,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": 50257,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_decoder_ids\": [\n",
       "      [\n",
       "        1,\n",
       "        50259\n",
       "      ],\n",
       "      [\n",
       "        2,\n",
       "        50359\n",
       "      ],\n",
       "      [\n",
       "        3,\n",
       "        50363\n",
       "      ]\n",
       "    ],\n",
       "    \"forced_eos_token_id\": null,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"init_std\": 0.02,\n",
       "    \"is_decoder\": false,\n",
       "    \"is_encoder_decoder\": true,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"mask_feature_length\": 10,\n",
       "    \"mask_feature_min_masks\": 0,\n",
       "    \"mask_feature_prob\": 0.0,\n",
       "    \"mask_time_length\": 10,\n",
       "    \"mask_time_min_masks\": 2,\n",
       "    \"mask_time_prob\": 0.05,\n",
       "    \"max_length\": 448,\n",
       "    \"max_source_positions\": 1500,\n",
       "    \"max_target_positions\": 448,\n",
       "    \"median_filter_width\": 7,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"whisper\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 12,\n",
       "    \"num_mel_bins\": 80,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": 50257,\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"scale_embedding\": false,\n",
       "    \"sep_token_id\": null,\n",
       "    \"suppress_tokens\": [\n",
       "      1,\n",
       "      2,\n",
       "      7,\n",
       "      8,\n",
       "      9,\n",
       "      10,\n",
       "      14,\n",
       "      25,\n",
       "      26,\n",
       "      27,\n",
       "      28,\n",
       "      29,\n",
       "      31,\n",
       "      58,\n",
       "      59,\n",
       "      60,\n",
       "      61,\n",
       "      62,\n",
       "      63,\n",
       "      90,\n",
       "      91,\n",
       "      92,\n",
       "      93,\n",
       "      359,\n",
       "      503,\n",
       "      522,\n",
       "      542,\n",
       "      873,\n",
       "      893,\n",
       "      902,\n",
       "      918,\n",
       "      922,\n",
       "      931,\n",
       "      1350,\n",
       "      1853,\n",
       "      1982,\n",
       "      2460,\n",
       "      2627,\n",
       "      3246,\n",
       "      3253,\n",
       "      3268,\n",
       "      3536,\n",
       "      3846,\n",
       "      3961,\n",
       "      4183,\n",
       "      4667,\n",
       "      6585,\n",
       "      6647,\n",
       "      7273,\n",
       "      9061,\n",
       "      9383,\n",
       "      10428,\n",
       "      10929,\n",
       "      11938,\n",
       "      12033,\n",
       "      12331,\n",
       "      12562,\n",
       "      13793,\n",
       "      14157,\n",
       "      14635,\n",
       "      15265,\n",
       "      15618,\n",
       "      16553,\n",
       "      16604,\n",
       "      18362,\n",
       "      18956,\n",
       "      20075,\n",
       "      21675,\n",
       "      22520,\n",
       "      26130,\n",
       "      26161,\n",
       "      26435,\n",
       "      28279,\n",
       "      29464,\n",
       "      31650,\n",
       "      32302,\n",
       "      32470,\n",
       "      36865,\n",
       "      42863,\n",
       "      47425,\n",
       "      49870,\n",
       "      50254,\n",
       "      50258,\n",
       "      50360,\n",
       "      50361,\n",
       "      50362\n",
       "    ],\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": true,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": \"bfloat16\",\n",
       "    \"torchscript\": false,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"use_weighted_layer_sum\": false,\n",
       "    \"vocab_size\": 51865\n",
       "  },\n",
       "  \"audio_select_layer\": -2,\n",
       "  \"llm_config\": {\n",
       "    \"_name_or_path\": \"mesolitica/malaysian-mistral-7b-32k-instructions-v4\",\n",
       "    \"add_cross_attention\": false,\n",
       "    \"architectures\": [\n",
       "      \"MistralForCausalLM\"\n",
       "    ],\n",
       "    \"attention_dropout\": 0.0,\n",
       "    \"bad_words_ids\": null,\n",
       "    \"begin_suppress_tokens\": null,\n",
       "    \"bos_token_id\": 1,\n",
       "    \"chunk_size_feed_forward\": 0,\n",
       "    \"cross_attention_hidden_size\": null,\n",
       "    \"decoder_start_token_id\": null,\n",
       "    \"diversity_penalty\": 0.0,\n",
       "    \"do_sample\": false,\n",
       "    \"early_stopping\": false,\n",
       "    \"encoder_no_repeat_ngram_size\": 0,\n",
       "    \"eos_token_id\": 2,\n",
       "    \"exponential_decay_length_penalty\": null,\n",
       "    \"finetuning_task\": null,\n",
       "    \"forced_bos_token_id\": null,\n",
       "    \"forced_eos_token_id\": null,\n",
       "    \"hidden_act\": \"silu\",\n",
       "    \"hidden_size\": 4096,\n",
       "    \"id2label\": {\n",
       "      \"0\": \"LABEL_0\",\n",
       "      \"1\": \"LABEL_1\"\n",
       "    },\n",
       "    \"initializer_range\": 0.02,\n",
       "    \"intermediate_size\": 14336,\n",
       "    \"is_decoder\": false,\n",
       "    \"is_encoder_decoder\": false,\n",
       "    \"label2id\": {\n",
       "      \"LABEL_0\": 0,\n",
       "      \"LABEL_1\": 1\n",
       "    },\n",
       "    \"length_penalty\": 1.0,\n",
       "    \"max_length\": 20,\n",
       "    \"max_position_embeddings\": 32768,\n",
       "    \"min_length\": 0,\n",
       "    \"model_type\": \"mistral\",\n",
       "    \"no_repeat_ngram_size\": 0,\n",
       "    \"num_attention_heads\": 32,\n",
       "    \"num_beam_groups\": 1,\n",
       "    \"num_beams\": 1,\n",
       "    \"num_hidden_layers\": 32,\n",
       "    \"num_key_value_heads\": 8,\n",
       "    \"num_return_sequences\": 1,\n",
       "    \"output_attentions\": false,\n",
       "    \"output_hidden_states\": false,\n",
       "    \"output_scores\": false,\n",
       "    \"pad_token_id\": null,\n",
       "    \"prefix\": null,\n",
       "    \"problem_type\": null,\n",
       "    \"pruned_heads\": {},\n",
       "    \"remove_invalid_values\": false,\n",
       "    \"repetition_penalty\": 1.0,\n",
       "    \"return_dict\": true,\n",
       "    \"return_dict_in_generate\": false,\n",
       "    \"rms_norm_eps\": 1e-05,\n",
       "    \"rope_theta\": 10000.0,\n",
       "    \"sep_token_id\": null,\n",
       "    \"sliding_window\": 4096,\n",
       "    \"suppress_tokens\": null,\n",
       "    \"task_specific_params\": null,\n",
       "    \"temperature\": 1.0,\n",
       "    \"tf_legacy_loss\": false,\n",
       "    \"tie_encoder_decoder\": false,\n",
       "    \"tie_word_embeddings\": false,\n",
       "    \"tokenizer_class\": null,\n",
       "    \"top_k\": 50,\n",
       "    \"top_p\": 1.0,\n",
       "    \"torch_dtype\": \"bfloat16\",\n",
       "    \"torchscript\": false,\n",
       "    \"typical_p\": 1.0,\n",
       "    \"use_bfloat16\": false,\n",
       "    \"use_cache\": true,\n",
       "    \"vocab_size\": 32004\n",
       "  },\n",
       "  \"model_type\": \"mm_llms\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.37.2\"\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56e59fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08fdb43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "audio_processor = AutoProcessor.from_pretrained('mesolitica/malaysian-whisper-small')\n",
    "tokenizer = AutoTokenizer.from_pretrained(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cced9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.llm.generation_config.eos_token_id = tokenizer.eos_token_id\n",
    "model.llm.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b385ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import librosa\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections.abc import Mapping\n",
    "\n",
    "class DataCollator():\n",
    "\n",
    "    def __init__(self, tokenizer):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, features):\n",
    "\n",
    "        if not isinstance(features[0], Mapping):\n",
    "            features = [vars(f) for f in features]\n",
    "\n",
    "        batch = {}\n",
    "        bs = len(features)\n",
    "        first = features[0]\n",
    "\n",
    "        batch['audio_index'] = torch.tensor([],dtype=torch.int)\n",
    "        \n",
    "        for index, feature in enumerate(features):\n",
    "            local_index = index % (bs) \n",
    "\n",
    "            if feature['audios'] is not None:\n",
    "                batch['audio_index'] = torch.cat([batch['audio_index'], torch.tensor(\n",
    "                    [local_index] * len(feature['audios']), dtype=torch.int)])\n",
    "\n",
    "        for k, v in first.items():\n",
    "\n",
    "            if k not in (\"audios\",\"images\") and not isinstance(v, str):\n",
    "                if v is None:\n",
    "                    batch[k] = None\n",
    "                elif isinstance(v, torch.Tensor):\n",
    "                    batch[k] = torch.stack([f[k] for f in features]).squeeze(1)\n",
    "                elif isinstance(v, np.ndarray):\n",
    "                    batch[k] = torch.tensor(np.stack([f[k] for f in features])).squeeze(1)\n",
    "            elif k in (\"audios\",\"images\"):\n",
    "                if v is None:\n",
    "                    batch[k] = None\n",
    "                else:         \n",
    "                    batch[k] = torch.cat([f[k] for f in features if f[k] is not None])\n",
    "\n",
    "        batch['audio_starts'] = torch.tensor(\n",
    "            [self.tokenizer.convert_tokens_to_ids('<audio>')] * bs, dtype=torch.int)\n",
    "        batch['audio_ends'] = torch.tensor(\n",
    "            [self.tokenizer.convert_tokens_to_ids('</audio>')] * bs, dtype=torch.int)\n",
    "\n",
    "        return batch\n",
    "\n",
    "collator = DataCollator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e2279b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(messages, audio: List[str] = None, sr = 16000):\n",
    "    if audio is not None:\n",
    "        audio = [librosa.load(f, sr=sr)[0] for f in audio]\n",
    "        audio_features = audio_processor(audio, sampling_rate=sr, return_tensors='pt',)['input_features']\n",
    "    else:\n",
    "        audio_features = None\n",
    "    \n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize = False)\n",
    "    outputs = tokenizer(\n",
    "                    prompt,\n",
    "                    return_tensors='pt',\n",
    "                    return_overflowing_tokens=False,\n",
    "                    return_length=False)\n",
    "\n",
    "    outputs['audios'] = audio_features\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46803884",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {'role': 'user', 'content': '<audio> </audio> audio ni tentang apa'},\n",
    "]\n",
    "outputs = prepare_dataset(messages, audio = ['test.mp3'])\n",
    "ok = collator([outputs])\n",
    "ok['labels'] = ok['input_ids']\n",
    "\n",
    "for k in ok.keys():\n",
    "    if ok[k] is not None:\n",
    "        ok[k] = ok[k].cuda()\n",
    "        \n",
    "for k in ['audios']:\n",
    "    if ok[k] is not None:\n",
    "        ok[k] = ok[k].type(model.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1830b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 16]), torch.Size([1, 503, 4096]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model_inputs = model.prepare_inputs_for_generation(**ok)\n",
    "r = model_inputs.pop('input_ids', None)\n",
    "label = model_inputs.pop('labels', None)\n",
    "label = label.detach().cpu().numpy()\n",
    "ok['input_ids'].shape, model_inputs['inputs_embeds'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "718c0b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/utils/hub.py:667: UserWarning: The `organization` argument is deprecated and will be removed in v5 of Transformers. Set your organization directly in the `repo_id` passed instead (`repo_id={organization}/{model_id}`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b86b442ed241b4be107b221287021f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d8bd7bb66844048b2202d2fbf8fe7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a614584f3fc54f678b4f49a99750eb41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/285M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23b8df5dd924bada56e26fb7de8027a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9985aab0719c4469810a4b58551689b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-mistral-malaysian-whisper-small-audio-alignment/commit/fb8e179382ab387fc46cabb9c8a529190acdb1f3', commit_message='Upload MM_LLMs', commit_description='', oid='fb8e179382ab387fc46cabb9c8a529190acdb1f3', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('malaysian-mistral-malaysian-whisper-small-audio-alignment', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98862dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/utils/hub.py:667: UserWarning: The `organization` argument is deprecated and will be removed in v5 of Transformers. Set your organization directly in the `repo_id` passed instead (`repo_id={organization}/{model_id}`).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3226f3a4cfe144e5bd6b40f8f01aa0fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-mistral-malaysian-whisper-small-audio-alignment/commit/c3bc88e628878d7f1e0418ad23cccaaabd1b9fe0', commit_message='Upload processor', commit_description='', oid='c3bc88e628878d7f1e0418ad23cccaaabd1b9fe0', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_processor.push_to_hub('malaysian-mistral-malaysian-whisper-small-audio-alignment', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfa9233d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/mesolitica/malaysian-mistral-malaysian-whisper-small-audio-alignment/commit/dba5b3b9c9feaed3b90ec4c49c7160574896e21e', commit_message='Upload tokenizer', commit_description='', oid='dba5b3b9c9feaed3b90ec4c49c7160574896e21e', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub('malaysian-mistral-malaysian-whisper-small-audio-alignment', organization='mesolitica', safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b9ba92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
